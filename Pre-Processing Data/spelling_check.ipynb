{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYFUkW7RVw9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24420dcb-e965-43ac-f3be-3557220b835c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-QwV1duVzhm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Tugas Akhir/dataset_with_spelling_check.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtAB4WTUV8dD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6ba42743-654c-45e0-e692-1bd413e68937"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1561f923cc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'komentar'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'komentar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "#Melakukan tokenize berdasarkan white space\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "data['komentar'] = data['komentar'].apply(str)\n",
        "\n",
        "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
        "comments = []\n",
        "for comment in data['komentar']:\n",
        "    comments.append(tokenizer.tokenize(comment))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan tokenize berdasarkan white space\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = \"makanya rezim jokowi minta tunda pemilu biar bisa utang lagi gampang koq\"\n",
        "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
        "token= tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "htpHvdWj36O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token"
      ],
      "metadata": {
        "id": "_MUVUOy24MU_",
        "outputId": "bc852112-4c4b-4c78-8cb1-9336ff83faf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['makanya',\n",
              " 'rezim',\n",
              " 'jokowi',\n",
              " 'minta',\n",
              " 'tunda',\n",
              " 'pemilu',\n",
              " 'biar',\n",
              " 'bisa',\n",
              " 'utang',\n",
              " 'lagi',\n",
              " 'gampang',\n",
              " 'koq']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "hSJOYpgxWJ_4",
        "outputId": "7ab25b8e-9af8-4b7d-a128-9ec3bd777cc0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c561a76d7740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
          ]
        }
      ],
      "source": [
        "comments[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WlJ5c3iWWYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "96727f5c-f9d2-4697-e006-4c1855fab1c8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7ab5b5c84b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Filter dari invalid caracter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'�'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
          ]
        }
      ],
      "source": [
        "#Filter dari invalid caracter\n",
        "invalid = '�'\n",
        "for i in range(0, len(comments)):\n",
        "    comment = comments[i]\n",
        "    for j in range(0, len(comment)):\n",
        "        sub_comment = comments[i][j]\n",
        "        for k in sub_comment:\n",
        "            if k in invalid:\n",
        "                comments[i][j] = comments[i][j].replace(k, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps6XUwMCWeih"
      },
      "outputs": [],
      "source": [
        "#Menghilangkan token yang kosong\n",
        "for comment in comments:\n",
        "    for sub_comment in comment:\n",
        "        if sub_comment == '':\n",
        "            comment.remove(sub_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2PgKqFBWg6k"
      },
      "outputs": [],
      "source": [
        "comments[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu2binMBX5Qj"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzrTTdkgXOyN"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrLcrvSPWkcw"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "path = F\"/content/drive/My Drive/Tugas Akhir/idwiki_word2vec_200_new_lower.model\"\n",
        "model = Word2Vec.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF0Qvg5_XXSH"
      },
      "outputs": [],
      "source": [
        "#Memproses data slang\n",
        "slang_corpus = pd.read_csv(\"/content/drive/My Drive/Tugas Akhir/slang.csv\")\n",
        "slang_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fioCT1Z5YGzC"
      },
      "outputs": [],
      "source": [
        "#Filter data slang\n",
        "slang_corpus = slang_corpus[slang_corpus.columns[0:2]]\n",
        "slang_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFhLkHW7WX9N"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhPXbFM_YI4K"
      },
      "outputs": [],
      "source": [
        "#Menggunakan perbandingan dengan word2vec yang ada dan edit distance untuk membuat kata menjadi kata formal\n",
        "import time\n",
        "from datetime import timedelta\n",
        "print(\"Processing data...\")\n",
        "start_time = time.time()\n",
        "import nltk\n",
        "corr_comments = []\n",
        "slang_words = []\n",
        "reco_words = []\n",
        "corr_word = 0\n",
        "tot_word = 0\n",
        "for comment in comments:\n",
        "    corr_comment = []\n",
        "    slang_word = []\n",
        "    for sub_comment in comment:\n",
        "        if sub_comment in model.wv.index_to_key:\n",
        "            sim_slang = slang_corpus[slang_corpus['slang'] == sub_comment]\n",
        "            if len(sim_slang) != 0:\n",
        "                mode_word = sim_slang.formal.mode()[0]\n",
        "                corr_word = corr_word + 1\n",
        "                corr_comment.append(mode_word)\n",
        "            else:\n",
        "                corr_word = corr_word + 1\n",
        "                corr_comment.append(sub_comment)\n",
        "        else:\n",
        "            comment_found = False\n",
        "            sim_slang = slang_corpus[slang_corpus['slang'] == sub_comment]\n",
        "            if len(sim_slang) != 0:\n",
        "                mode_word = sim_slang.formal.mode()[0]\n",
        "                corr_word = corr_word + 1\n",
        "                corr_comment.append(mode_word)\n",
        "                comment_found = True\n",
        "            else:\n",
        "                rat_words = []\n",
        "                for slang in slang_corpus['slang']:\n",
        "                    rat_word = nltk.edit_distance(sub_comment, slang)\n",
        "                    rat_words.append(rat_word)\n",
        "                min_rat = rat_words.index(min(rat_words))\n",
        "                value = str(slang_corpus.formal.loc[min_rat])\n",
        "                corr_words = corr_word + 1\n",
        "                corr_comment.append(value)\n",
        "                slang_words.append(sub_comment + \" = \" + value)\n",
        "                comment_found = True\n",
        "            if comment_found ==  False:\n",
        "                corr_comment.append(sub_comment)\n",
        "                slang_words.append(sub_comment + \" = \" + \"Not Found\")\n",
        "        tot_word = tot_word + 1\n",
        "    corr_comments.append(corr_comment)\n",
        "    print(\"Total kata yang sudah diproses : \" + str(tot_word))\n",
        "print(\"Total kata yang diperbaiki : \" + str(corr_word) + \" dari total semua kata : \" + str(tot_word))\n",
        "finish_time = time.time()\n",
        "print('Elapsed time: {}'.format(timedelta(seconds=finish_time-start_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZSdKIAWYPPu"
      },
      "outputs": [],
      "source": [
        "data['komentar'] = corr_comments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def join(text):\n",
        "    text  = \" \".join([char for char in text if char not in string.punctuation])\n",
        "    return text"
      ],
      "metadata": {
        "id": "o3mAkYqrDnt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48brFMPUqJM1"
      },
      "outputs": [],
      "source": [
        "data['komentar'] = data['komentar'].apply(lambda x: join(x))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vQu7h4gppzn"
      },
      "outputs": [],
      "source": [
        "data['komentar''] = data['komentar''].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1XDdHe-YqW2"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"dataset_sc.csv\")  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}